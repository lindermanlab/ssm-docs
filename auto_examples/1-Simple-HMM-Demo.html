
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Simple HMM Demo &#8212; ssm  documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Simple Linear Dynamical System Demo" href="1b-Simple-Linear-Dynamical-System.html" />
    <link rel="prev" title="Welcome to ssmâ€™s documentation!" href="../index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">ssm  documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Simple HMM Demo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1b-Simple-Linear-Dynamical-System.html">
   Simple Linear Dynamical System Demo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2-Input-Driven-HMM.html">
   Input Driven HMM
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2b-Input-Driven-Observations-%28GLM-HMM%29.html">
   Input Driven Observations (GLM-HMM)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3-Switching-Linear-Dynamical-System.html">
   Switching Linear Dynamical System
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="4-Recurrent-SLDS.html">
   Recurrent SLDS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="5-Poisson-SLDS.html">
   Poisson SLDS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="6-Poisson-fLDS.html">
   Poisson fLDS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="7-Variatonal-Laplace-EM-for-SLDS-Tutorial.html">
   Variational Laplace EM for SLDS
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="HMM-State-Clustering.html">
   HMM State Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Multi-Population-rSLDS.html">
   Multi-Population rSLDS
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/auto_examples/1-Simple-HMM-Demo.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Simple HMM Demo</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-1-simple-hmm-demo-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="simple-hmm-demo">
<span id="sphx-glr-auto-examples-1-simple-hmm-demo-py"></span><h1>Simple HMM Demo<a class="headerlink" href="#simple-hmm-demo" title="Permalink to this headline">#</a></h1>
<ul class="sphx-glr-horizontal">
<li><img src="../_images/sphx_glr_1-Simple-HMM-Demo_001.png" srcset="../_images/sphx_glr_1-Simple-HMM-Demo_001.png" alt="Observation Distributions" class = "sphx-glr-multi-img"/></li>
<li><img src="../_images/sphx_glr_1-Simple-HMM-Demo_002.png" srcset="../_images/sphx_glr_1-Simple-HMM-Demo_002.png" alt="Simulated data from an HMM" class = "sphx-glr-multi-img"/></li>
<li><img src="../_images/sphx_glr_1-Simple-HMM-Demo_003.png" srcset="../_images/sphx_glr_1-Simple-HMM-Demo_003.png" alt="1 Simple HMM Demo" class = "sphx-glr-multi-img"/></li>
<li><img src="../_images/sphx_glr_1-Simple-HMM-Demo_004.png" srcset="../_images/sphx_glr_1-Simple-HMM-Demo_004.png" alt="1 Simple HMM Demo" class = "sphx-glr-multi-img"/></li>
<li><img src="../_images/sphx_glr_1-Simple-HMM-Demo_005.png" srcset="../_images/sphx_glr_1-Simple-HMM-Demo_005.png" alt="True Transition Matrix, Learned Transition Matrix" class = "sphx-glr-multi-img"/></li>
<li><img src="../_images/sphx_glr_1-Simple-HMM-Demo_006.png" srcset="../_images/sphx_glr_1-Simple-HMM-Demo_006.png" alt="Histogram of True State Durations" class = "sphx-glr-multi-img"/></li>
<li><img src="../_images/sphx_glr_1-Simple-HMM-Demo_007.png" srcset="../_images/sphx_glr_1-Simple-HMM-Demo_007.png" alt="Histogram of Inferred State Durations" class = "sphx-glr-multi-img"/></li>
</ul>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -845.3:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -845.3:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -705.0:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -693.6:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -686.4:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -681.0:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -675.9:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -670.2:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -662.5:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -654.0:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -649.1:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -647.0:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -646.1:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -641.7:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -636.8:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -636.8:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -636.4:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -634.6:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -631.8:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -631.2:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -631.1:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -631.0:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -630.4:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -626.2:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -623.0:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -623.0:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -623.0:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -623.0:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -623.0:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -623.0:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -623.0:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.9:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.9:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.9:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.9:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.9:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.9:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.9:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.9:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.8:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.7:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.6:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.4:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.2:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.1:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.1:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.1:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.0:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.0:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.0:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.0:   0%|          | 0/50 [00:00&lt;?, ?it/s]
LP: -622.0: 100%|##########| 50/50 [00:00&lt;00:00, 1303.88it/s]
</pre></div>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;5918355f-c759-41e8-9cc9-64baf78695b3&quot;}</span>
<span class="c1"># # Hidden Markov Model Demo</span>

<span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;2b6476b4-bceb-48bc-8957-e943d943c162&quot;}</span>
<span class="c1"># A Hidden Markov Model (HMM) is one of the simpler graphical models available in _SSM_. This notebook demonstrates creating and sampling from and HMM using SSM, and fitting an HMM to synthetic data. A full treatment of HMMs is beyond the scope of this notebook, but there are many good resources. [Stanford&#39;s CS228 Lecture Notes](https://ermongroup.github.io/cs228-notes/) provide a good introduction to HMMs and other graphical models. [Pattern Recognition and Machine Learning](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf) by Christopher Bishop covers HMMs and how the EM algorithm is used to fit them from data.</span>
<span class="c1">#</span>
<span class="c1">#</span>
<span class="c1"># The goal of these notebooks is to introduce state-space models to practitioners who have some familiarity with them, but who may not have used these models in practice before. As such, we&#39;ve included a few exercises to try as you make your way through the notebooks.</span>

<span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;7aec52f3-b963-4afb-b2a4-444b30304575&quot;}</span>
<span class="c1"># ## 1. Setup</span>
<span class="c1"># The line `import ssm` imports the package for use. Here, we have also imported a few other packages for plotting.</span>

<span class="c1"># + nbpresent={&quot;id&quot;: &quot;346a61a3-9216-480d-b5b8-39a78782a8c3&quot;}</span>
<span class="kn">import</span> <span class="nn">autograd.numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">autograd.numpy.random</span> <span class="k">as</span> <span class="nn">npr</span>
<span class="n">npr</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">ssm</span>
<span class="kn">from</span> <span class="nn">ssm.util</span> <span class="kn">import</span> <span class="n">find_permutation</span>
<span class="kn">from</span> <span class="nn">ssm.plots</span> <span class="kn">import</span> <span class="n">gradient_cmap</span><span class="p">,</span> <span class="n">white_to_color_cmap</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1"># %matplotlib inline</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s2">&quot;talk&quot;</span><span class="p">)</span>

<span class="n">color_names</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;windows blue&quot;</span><span class="p">,</span>
    <span class="s2">&quot;red&quot;</span><span class="p">,</span>
    <span class="s2">&quot;amber&quot;</span><span class="p">,</span>
    <span class="s2">&quot;faded green&quot;</span><span class="p">,</span>
    <span class="s2">&quot;dusty purple&quot;</span><span class="p">,</span>
    <span class="s2">&quot;orange&quot;</span>
    <span class="p">]</span>

<span class="n">colors</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">xkcd_palette</span><span class="p">(</span><span class="n">color_names</span><span class="p">)</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">gradient_cmap</span><span class="p">(</span><span class="n">colors</span><span class="p">)</span>


<span class="c1"># Speficy whether or not to save figures</span>
<span class="n">save_figures</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;e6b9c054-f24c-4271-85b5-0a8e795dc333&quot;}</span>
<span class="c1"># ## 2. Create an HMM</span>
<span class="c1"># An HMM consists of a set of hidden state variable, $z$, which can take on one of $K$ values (for our purposes, HMMs will always have discrete states), along with a set of transition probabilities for how the hidden state evolves over time.</span>
<span class="c1"># In other words, we have $z_t \in \{1, \ldots, K\}$, where $z_t = k$ denotes that the hidden variable is in state $k$ at time $t$.</span>
<span class="c1">#</span>
<span class="c1">#</span>
<span class="c1"># The key assumption in an HMM is that only the most recent state affects the next state. In mathematical terms:</span>
<span class="c1">#</span>
<span class="c1"># $$</span>
<span class="c1"># p(z_t \mid z_{t-1}, z_{t-2}, \ldots, z_1) = p(z_t \mid z_{t-1})</span>
<span class="c1"># $$</span>
<span class="c1">#</span>
<span class="c1"># In an HMM, we don&#39;t observe the state itself. Instead, we get a noisy observation of the state at each time step according to some observation model. We&#39;ll use $x_t$ to denote the observation at time step $t$. The observation can be a vector or scalar. We&#39;ll use $D$ to refer to the dimensionality of the observation. A few of the supported observation models are:</span>
<span class="c1">#</span>
<span class="c1"># 1. **Gaussian**: Each discrete state $z_t = k$ is associated with a $D$-dimensional mean $\mu_k$ and covariance matrix $\Sigma_k$. Each observation $z_t$ comes from a Gaussian distribution centered at the associated mean, with the corresponding covariance.</span>
<span class="c1">#</span>
<span class="c1"># 2. **Student&#39;s T**: Same as Gaussian, but the observations come from a Student&#39;s-T Distribution.</span>
<span class="c1">#</span>
<span class="c1"># 3. **Bernoulli**: Each element of the $D$-dimensional observation is a Bernoulli (binary) random variable. Each discrete state $Z_i$ determines the probability that each element in the observation is nonzero.</span>
<span class="c1">#</span>
<span class="c1"># _Note: SSM supports many other observation models for HMMs. We are in the process of creating full-standalone documentation to describe them. For now, the best way to learn about SSM&#39;s other functionality is look at the source code. The observation models are described in observations.py._</span>
<span class="c1">#</span>
<span class="c1">#</span>
<span class="c1"># In the below example, we create an instance of the HMM with 5 discrete states and 2 dimensional observations. We store our HMM instance in a variable called true_hmm with this line:</span>
<span class="c1">#</span>
<span class="c1"># `</span>
<span class="c1"># true_hmm = ssm.HMM(K, D, observations=&quot;gaussian&quot;)</span>
<span class="c1"># `</span>
<span class="c1">#</span>
<span class="c1"># We then manually set the means for each latent state to make them farther away (this makes them easier to visualize).</span>
<span class="c1">#</span>
<span class="c1"># `</span>
<span class="c1"># true_hmm.observations.mus = 3 * np.column_stack((np.cos(thetas), np.sin(thetas)))</span>
<span class="c1"># `</span>
<span class="c1">#</span>
<span class="c1"># Here we are modifying the `observations` instance associated with the HMM we created above. We could also change the covariance, but for now we&#39;re leaving it with the default (identity covariance).</span>

<span class="c1"># + nbpresent={&quot;id&quot;: &quot;564edd16-a99d-4329-8e31-98fe1e1cef79&quot;}</span>
<span class="c1"># Set the parameters of the HMM</span>
<span class="n">time_bins</span> <span class="o">=</span> <span class="mi">200</span>   <span class="c1"># number of time bins</span>
<span class="n">num_states</span> <span class="o">=</span> <span class="mi">5</span>    <span class="c1"># number of discrete states</span>
<span class="n">obs_dim</span> <span class="o">=</span> <span class="mi">2</span>       <span class="c1"># dimensionality of observation</span>

<span class="c1"># Make an HMM</span>
<span class="n">true_hmm</span> <span class="o">=</span> <span class="n">ssm</span><span class="o">.</span><span class="n">HMM</span><span class="p">(</span><span class="n">num_states</span><span class="p">,</span> <span class="n">obs_dim</span><span class="p">,</span> <span class="n">observations</span><span class="o">=</span><span class="s2">&quot;gaussian&quot;</span><span class="p">)</span>

<span class="c1"># Manually tweak the means to make them farther apart</span>
<span class="n">thetas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">num_states</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">true_hmm</span><span class="o">.</span><span class="n">observations</span><span class="o">.</span><span class="n">mus</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">thetas</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">thetas</span><span class="p">)))</span>

<span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;846d39dd-47a8-4b70-860f-6943eb17fc7a&quot;}</span>
<span class="c1"># ## 3. Sample from the HMM</span>
<span class="c1">#</span>
<span class="c1"># We draw samples from an HMM using the `sample` method:</span>
<span class="c1"># `true_states, obs = true_hmm.sample(time_bins)`.</span>
<span class="c1">#</span>
<span class="c1"># This returns a tuple $(z, x)$ of the latent states and observations, respectively.</span>
<span class="c1"># In this case, `true_states` will be an array of size $(200,)$ because it contains the discrete state $z_t$ across $200$ time-bins. `obs` will be an array of size $(200, 2)$ because it contains the observations across $200$ time bins, and each observation is two dimensional.</span>
<span class="c1"># We have specified the number of time-steps by passing `time_bins` as the argument to the `sample` method.</span>
<span class="c1">#</span>
<span class="c1"># In the next line, we retrieve the log-likelihood of the data we observed:</span>
<span class="c1"># `true_ll = true_hmm.log_probability(obs)`</span>
<span class="c1">#</span>
<span class="c1"># This tells us the relative probability of our observations. In the next section, when we fit an HMM to the data we generated, the true log-likelihood will be helpful for determining if our fitting algorithm succeeded.</span>

<span class="c1"># + nbpresent={&quot;id&quot;: &quot;c441ffc6-38cb-4933-97b2-f62897046fd6&quot;}</span>
<span class="c1"># Sample some data from the HMM</span>
<span class="n">true_states</span><span class="p">,</span> <span class="n">obs</span> <span class="o">=</span> <span class="n">true_hmm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">time_bins</span><span class="p">)</span>
<span class="n">true_ll</span> <span class="o">=</span> <span class="n">true_hmm</span><span class="o">.</span><span class="n">log_probability</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>

<span class="c1"># + nbpresent={&quot;id&quot;: &quot;c9b4a46a-2f86-4b7f-adb6-70c667a1ac67&quot;}</span>
<span class="c1"># Plot the observation distributions</span>
<span class="n">lim</span> <span class="o">=</span> <span class="mf">.85</span> <span class="o">*</span> <span class="nb">abs</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">XX</span><span class="p">,</span> <span class="n">YY</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">lim</span><span class="p">,</span> <span class="n">lim</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">lim</span><span class="p">,</span> <span class="n">lim</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">XX</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">YY</span><span class="o">.</span><span class="n">ravel</span><span class="p">()))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">tag</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">lls</span> <span class="o">=</span> <span class="n">true_hmm</span><span class="o">.</span><span class="n">observations</span><span class="o">.</span><span class="n">log_likelihoods</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">tag</span><span class="p">)</span>

<span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;a201a5b1-0cff-4e1f-9367-c25a89ebac41&quot;}</span>
<span class="c1"># Below, we plot the samples obtained from the HMM, color-coded according to the underlying state. The solid curves show regions of of equal probability density around each mean. The thin gray lines trace the latent variable as it transitions from one state to another.</span>

<span class="c1"># + nbpresent={&quot;id&quot;: &quot;0feabc13-812b-4d5e-ac24-f8327ecb4d27&quot;}</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_states</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">lls</span><span class="p">[:,</span><span class="n">k</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">XX</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">white_to_color_cmap</span><span class="p">(</span><span class="n">colors</span><span class="p">[</span><span class="n">k</span><span class="p">]))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">obs</span><span class="p">[</span><span class="n">true_states</span><span class="o">==</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">obs</span><span class="p">[</span><span class="n">true_states</span><span class="o">==</span><span class="n">k</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">mfc</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">mec</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">obs</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">obs</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;-k&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$x_1$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;$x_2$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Observation Distributions&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">save_figures</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;hmm_1.pdf&quot;</span><span class="p">)</span>

<span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;a58c7a02-2777-4af8-982f-e279bd3bbeb6&quot;}</span>
<span class="c1"># Below, we visualize each component of of the observation variable as a time series. The colors correspond to the latent state. The dotted lines represent the &quot;true&quot; values of the observation variable (the mean) while the solid lines are the actual observations sampled from the HMM.</span>

<span class="c1"># + nbpresent={&quot;id&quot;: &quot;1ec5ac27-2d23-4660-8702-4156f8ffdf39&quot;}</span>
<span class="c1"># Plot the data and the smoothed data</span>
<span class="n">lim</span> <span class="o">=</span> <span class="mf">1.05</span> <span class="o">*</span> <span class="nb">abs</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">true_states</span><span class="p">[</span><span class="kc">None</span><span class="p">,:],</span>
           <span class="n">aspect</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
           <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span>
           <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
           <span class="n">vmax</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>
           <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">time_bins</span><span class="p">,</span> <span class="o">-</span><span class="n">lim</span><span class="p">,</span> <span class="p">(</span><span class="n">obs_dim</span><span class="p">)</span><span class="o">*</span><span class="n">lim</span><span class="p">))</span>

<span class="n">Ey</span> <span class="o">=</span> <span class="n">true_hmm</span><span class="o">.</span><span class="n">observations</span><span class="o">.</span><span class="n">mus</span><span class="p">[</span><span class="n">true_states</span><span class="p">]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">obs_dim</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">obs</span><span class="p">[:,</span><span class="n">d</span><span class="p">]</span> <span class="o">+</span> <span class="n">lim</span> <span class="o">*</span> <span class="n">d</span><span class="p">,</span> <span class="s1">&#39;-k&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Ey</span><span class="p">[:,</span><span class="n">d</span><span class="p">]</span> <span class="o">+</span> <span class="n">lim</span> <span class="o">*</span> <span class="n">d</span><span class="p">,</span> <span class="s1">&#39;:k&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">time_bins</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;time&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">lim</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">obs_dim</span><span class="p">),</span> <span class="p">[</span><span class="s2">&quot;$x_</span><span class="si">{}</span><span class="s2">$&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">d</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">obs_dim</span><span class="p">)])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Simulated data from an HMM&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="k">if</span> <span class="n">save_figures</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;hmm_2.pdf&quot;</span><span class="p">)</span>

<span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;093b73b4-65a9-40ac-83ba-334a10736e01&quot;}</span>
<span class="c1"># ### Exercise 3.1: Change the observation model</span>
<span class="c1"># Try changing the observation model to Bernoulli and visualizing the sampled data. You&#39;ll need to create a new HMM object with Bernoulli observations. Then, use the `sample` method to sample from it. Visualizing the mean vectors and contours makes sense for Gaussian observations, but might not be the best way to visualize Bernoulli observations.</span>

<span class="c1"># + nbpresent={&quot;id&quot;: &quot;74a8cecc-d647-4921-bb7e-4037d89065ea&quot;}</span>
<span class="c1"># Your code here: create an HMM with Bernoulli observations</span>
<span class="c1"># ---------------------------------------------------------</span>


<span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;759699ce-fffa-4667-90af-267122e39f01&quot;}</span>
<span class="c1"># # 4. Fit an HMM to synthetic data</span>
<span class="c1"># This is all fine, but so far we haven&#39;t done anything that useful. It&#39;s far more interesting to learn an HMM from data. In the following cells, we&#39;ll use the synthetic data we generated above to fit an HMM from scratch. This is done in the following lines:</span>
<span class="c1">#</span>
<span class="c1"># `</span>
<span class="c1"># hmm = ssm.HMM(num_states, obs_dim, observations=&quot;gaussian&quot;)</span>
<span class="c1"># hmm_lls = hmm.fit(obs, method=&quot;em&quot;, num_em_iters=N_iters)</span>
<span class="c1"># `</span>
<span class="c1">#</span>
<span class="c1"># In the first line, we create a new HMM instance called `hmm` with a gaussian observation model, as in the previous case. Because we haven&#39;t specified anything, the transition probabilities and observation means will be randomly initialized. In the next line, we use the `fit` method to learn the transition probabilities and observation means from data. We set the method to `em` (expectation maximization) and specify the maximum number of iterations which will be used to fit the data. The `fit` method returns a numpy array which shows the log-likelihood of the data over time. We then plot this and see that the EM algorithm quickly converges.</span>

<span class="c1"># + nbpresent={&quot;id&quot;: &quot;d9064e18-01ca-43d4-a866-1b796cc94297&quot;}</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">obs</span> <span class="c1"># Treat observations generated above as synthetic data.</span>
<span class="n">N_iters</span> <span class="o">=</span> <span class="mi">50</span>

<span class="c1">## testing the constrained transitions class</span>
<span class="n">hmm</span> <span class="o">=</span> <span class="n">ssm</span><span class="o">.</span><span class="n">HMM</span><span class="p">(</span><span class="n">num_states</span><span class="p">,</span> <span class="n">obs_dim</span><span class="p">,</span> <span class="n">observations</span><span class="o">=</span><span class="s2">&quot;gaussian&quot;</span><span class="p">)</span>

<span class="n">hmm_lls</span> <span class="o">=</span> <span class="n">hmm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;em&quot;</span><span class="p">,</span> <span class="n">num_iters</span><span class="o">=</span><span class="n">N_iters</span><span class="p">,</span> <span class="n">init_method</span><span class="o">=</span><span class="s2">&quot;kmeans&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">hmm_lls</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;EM&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">N_iters</span><span class="p">],</span> <span class="n">true_ll</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;:k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;EM Iteration&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Log Probability&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;f9335974-fcee-4a2e-827f-b22a12ed688f&quot;}</span>
<span class="c1"># The below cell is a bit subtle. In the first section, we sampled from the HMM and stored the resulting latent state $z$ in a variable called `state`.</span>
<span class="c1"># Now, we are treating our observations from the previous section as data, and seeing whether we can infer the true state given only the observations. However, there is no guarantee that the states we learn correspond to the original states from the true HMM. In order to account for this, we need to find a permutation of the states of our new HMM so that they align with the states of the true HMM from the prior section. This is done in the following two lines:</span>
<span class="c1">#</span>
<span class="c1"># `most_likely_states = hmm.most_likely_states(obs)</span>
<span class="c1"># hmm.permute(find_permutation(true_states, most_likely_states))</span>
<span class="c1"># `</span>
<span class="c1">#</span>
<span class="c1"># In the first line, we use the `most_likely_states` method to infer the most likely latent states given the observations.  In the second line we call the `find_permutation` function the permutation that best matches the true state. We then use the `permute` method on our `hmm` instance to permute its states accordingly.</span>
<span class="c1">#</span>
<span class="c1">#</span>

<span class="c1"># + nbpresent={&quot;id&quot;: &quot;35947156-e3a9-44d6-ab79-aea66d05cda7&quot;}</span>
<span class="c1"># Find a permutation of the states that best matches the true and inferred states</span>
<span class="n">most_likely_states</span> <span class="o">=</span> <span class="n">hmm</span><span class="o">.</span><span class="n">most_likely_states</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
<span class="n">hmm</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">find_permutation</span><span class="p">(</span><span class="n">true_states</span><span class="p">,</span> <span class="n">most_likely_states</span><span class="p">))</span>

<span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;03d4efcd-66a8-4e0b-8558-6df4658382d4&quot;}</span>
<span class="c1"># Below, we plot the inferred states ($z_{\mathrm{inferred}}$) and the true states ($z_{\mathrm{true}}$) over time. We see that the two match very closely, but not exactly. The model sometimes has difficulty inferring the state if we only observe that state for a very short time.</span>

<span class="c1"># + nbpresent={&quot;id&quot;: &quot;84b20c35-4187-4b2b-8287-c99212f17a4b&quot;}</span>
<span class="c1"># Plot the true and inferred discrete states</span>
<span class="n">hmm_z</span> <span class="o">=</span> <span class="n">hmm</span><span class="o">.</span><span class="n">most_likely_states</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">true_states</span><span class="p">[</span><span class="kc">None</span><span class="p">,:],</span> <span class="n">aspect</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">time_bins</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;$z_{</span><span class="se">\\</span><span class="s2">mathrm</span><span class="si">{true}</span><span class="s2">}$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">212</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">hmm_z</span><span class="p">[</span><span class="kc">None</span><span class="p">,:],</span> <span class="n">aspect</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">time_bins</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;$z_{</span><span class="se">\\</span><span class="s2">mathrm</span><span class="si">{inferred}</span><span class="s2">}$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;time&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;75818ecd-323a-4cdf-a52a-3703b3e82123&quot;}</span>
<span class="c1"># An HMM can also be used to smooth data (once its parameters are learned) but computing the mean observation under the posterior distribution of latent states.</span>
<span class="c1"># Let&#39;s say, for example, that during time steps 0 to 10 the model estimates a 0.3 probability of being in state 1, and a 0.7 probability of being in state 2, given the observations $x$.</span>
<span class="c1"># Mathematically, that&#39;s saying we&#39;ve computed the following probabilities:</span>
<span class="c1"># $$</span>
<span class="c1"># p(z=1 \mid X) = 0.3\\</span>
<span class="c1"># p(z=3 \mid X) = 0.7</span>
<span class="c1"># $$</span>
<span class="c1">#</span>
<span class="c1"># The smoothed observations would then be $0.3 \mu_1 + 0.7 \mu_2$, where we $\mu_i$ is the mean for the observations in state $i$.</span>
<span class="c1"># In the cell below, we use `hmm.smooth(obs)` to smooth the data this way. The orange and blue lines show the smoothed data, and the black lines show the original noisy observations.</span>

<span class="c1"># + nbpresent={&quot;id&quot;: &quot;69dc9764-e7bc-4ab5-80a3-ba107e323531&quot;}</span>
<span class="c1"># Use the HMM to &quot;smooth&quot; the data</span>
<span class="n">hmm_x</span> <span class="o">=</span> <span class="n">hmm</span><span class="o">.</span><span class="n">smooth</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">obs</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">obs_dim</span><span class="p">),</span> <span class="s1">&#39;-k&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">hmm_x</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">obs_dim</span><span class="p">),</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">time_bins</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;$x$&quot;</span><span class="p">)</span>
<span class="c1"># plt.yticks([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;time&quot;</span><span class="p">)</span>

<span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;747730ff-ab9a-4aff-9da4-6e7b203d2aa6&quot;}</span>
<span class="c1"># ### 4.1. Visualize the Transition Matrices</span>
<span class="c1"># The dynamics of the hidden state in an HMM are specified by the transition probabilities $p(z_t \mid z_{t-1})$. It&#39;s standard to pack these probabilities into a stochastic matrix $A$ where $A_{ij} = p(z_t = j \mid z_{t-1} = i)$.</span>
<span class="c1">#</span>
<span class="c1"># In SSM, we can access the transition matrices using `hmm.transitions.transition` matrix. In the following two lines, we retrives the transition matrices for the true HMM, as well as the HMM we learned from the data, and compare them visually.</span>

<span class="c1"># + nbpresent={&quot;id&quot;: &quot;67124d1b-c672-47a1-92cc-5538012bcd48&quot;}</span>
<span class="n">true_transition_mat</span> <span class="o">=</span> <span class="n">true_hmm</span><span class="o">.</span><span class="n">transitions</span><span class="o">.</span><span class="n">transition_matrix</span>
<span class="n">learned_transition_mat</span> <span class="o">=</span> <span class="n">hmm</span><span class="o">.</span><span class="n">transitions</span><span class="o">.</span><span class="n">transition_matrix</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">true_transition_mat</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;True Transition Matrix&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">learned_transition_mat</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Learned Transition Matrix&quot;</span><span class="p">)</span>

<span class="n">cbar_ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">([</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">cbar_ax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;e358a229-5f00-4a6c-9b13-011d2afff30c&quot;}</span>
<span class="c1"># ### Excercise 4.2: Distribution of State Durations</span>
<span class="c1"># Derive the theoretical distribution over state durations. Do the state durations we observe ($Z_{true}$ in section 4) match the theory? If you&#39;re stuck, imagine that the system starts in state $1$, i.e $z_1 = 1$. What&#39;s the probability that $z_2 = 1$? From here, you might be able to work forwards in time.</span>
<span class="c1">#</span>
<span class="c1"># When done, check if your derivation matches what we find in the section below.</span>

<span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;2a96744b-592a-4642-904f-27793f67d790&quot;}</span>
<span class="c1"># ### 4.3: Visualize State Durations</span>
<span class="c1">#</span>

<span class="c1"># + nbpresent={&quot;id&quot;: &quot;30e94251-7e72-42f6-9329-7f43500f5e05&quot;}</span>
<span class="n">true_state_list</span><span class="p">,</span> <span class="n">true_durations</span> <span class="o">=</span> <span class="n">ssm</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">rle</span><span class="p">(</span><span class="n">true_states</span><span class="p">)</span>
<span class="n">inferred_state_list</span><span class="p">,</span> <span class="n">inferred_durations</span> <span class="o">=</span> <span class="n">ssm</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">rle</span><span class="p">(</span><span class="n">hmm_z</span><span class="p">)</span>

<span class="c1"># Rearrange the lists of durations to be a nested list where</span>
<span class="c1"># the nth inner list is a list of durations for state n</span>
<span class="n">true_durs_stacked</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">inf_durs_stacked</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_states</span><span class="p">):</span>
    <span class="n">true_durs_stacked</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">true_durations</span><span class="p">[</span><span class="n">true_state_list</span> <span class="o">==</span> <span class="n">s</span><span class="p">])</span>
    <span class="n">inf_durs_stacked</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inferred_durations</span><span class="p">[</span><span class="n">inferred_state_list</span> <span class="o">==</span> <span class="n">s</span><span class="p">])</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">true_durs_stacked</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;state &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_states</span><span class="p">)])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Duration&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Histogram of True State Durations&#39;</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">inf_durs_stacked</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;state &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_states</span><span class="p">)])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Duration&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Histogram of Inferred State Durations&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;a36b24e0-89ce-401a-af4e-0303955ab0be&quot;}</span>
<span class="c1"># ### Excercise 4.4: Fit an HMM using more data</span>
<span class="c1"># We see that the above histograms do not match each other as closely as we might expect. They also don&#39;t match the theoretical distriubtion of durations all that closely (see Exercise 4.2). Part of the reason for this is that we have sampled from a relatively small number of time steps.</span>
<span class="c1">#</span>
<span class="c1"># Try modifying the `time_bins` variable to sample for more time-steps (say 2000 or so).</span>
<span class="c1"># Then, re-run the analysis above. Because of the larger time frame, some of the plots above may become hard to read, but the histogram of durations should more closely match what we expect.</span>

<span class="c1"># + [markdown] nbpresent={&quot;id&quot;: &quot;d93612d4-88a5-4c39-8d8d-b1ec4865ab70&quot;}</span>
<span class="c1"># ### Exercise 4.5: Mismatched Observations</span>
<span class="c1"># Imagine a scenario where the true data comes from an HMM with Student&#39;s T observations, but you fit an HMM with Gaussian observations. What might you expect to happen?</span>
<span class="c1">#</span>
<span class="c1"># You can try simulating this: modify the code in Section 2 so that we create and HMM with Student&#39;s T observations. Then re-run the cells in Section 4, which will fit an HMM with Gaussian observations to the observed data. What do you see?</span>
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.778 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-1-simple-hmm-demo-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/06fbc9ee7dd1d49654639c70d58321c3/1-Simple-HMM-Demo.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">1-Simple-HMM-Demo.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/dec301df8dee73bfa47c105887dc85c0/1-Simple-HMM-Demo.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">1-Simple-HMM-Demo.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../index.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Welcome to ssmâ€™s documentation!</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="1b-Simple-Linear-Dynamical-System.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Simple Linear Dynamical System Demo</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Scott Linderman<br/>
  
      &copy; Copyright 2022, Scott Linderman.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>