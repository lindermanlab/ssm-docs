{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c1b371",
   "metadata": {},
   "source": [
    "# Poisson HMM Demo\n",
    "\n",
    "Written by Benjamin Antin, Scott Linderman, and Krishna Shenoy.\n",
    "Thanks to [Caleb Kemere](http://rnel.rice.edu/) for sharing his data with us.\n",
    "  \n",
    "## Applying an HMM to electrophysiology data from a motor-control task\n",
    "\n",
    "In this notebook, we'll show how SSM can be used for modeling neuroscience data. This notebook is based off the 2008 paper [\"Detecting Neural-State Transitions Using Hidden Markov Models for Motor Cortical Prostheses\"](https://web.stanford.edu/~shenoy/GroupPublications/KemereEtAlJNeurophysiol2008.pdf) by Caleb Kemere _et al_.  \n",
    "\n",
    "  \n",
    "Kemere shows that an HMM can be used to detect neural transitions in a reaching task performed by a monkey. Crucially, by cleverly configuring the HMM states, the authors are also able to decode which target the monkey reached to using their trained HMM. See the paper for more details on the data and experimental set-up.\n",
    "  \n",
    "First, we need to load in the data. Though the data is not yet publicly available, we are hoping to make it available soon. We will assume that you have the dependencies included in SSM installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54920c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ssm-docs/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import block_diag\n",
    "import autograd.numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ssm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c915b",
   "metadata": {},
   "source": [
    "## 1. Background\n",
    "\n",
    "This dataset contains neural recordings made using a Utah array (96 electrodes) implanted in pre-motor cortex a macaque performing a reach task.\n",
    "During the task, the monkey must reach to one of 8 targets, as indicated by a cue on a screen.\n",
    "Each trial consists of 3 phases: a **baseline** phase, a **plan** phase, and a **move** phase.\n",
    "We describe these phases below:\n",
    "\n",
    "1. **baseline**: The animal fixates and places his hand in the center of the screen.\n",
    "2. **plan**: A target appears in one of 8 locations (radially spread out from the center of the screen).\n",
    "The monkey does not yet begin reaching.\n",
    "3. **move**: A go-cue comes on, telling the monkey to begin his reach. Upon successfully reaching the target, the monkey receives a liquid reward.\n",
    "\n",
    "The neural data has been spike-sorted and binned in 10ms intervals.  \n",
    "  \n",
    "**Note**: This data contains both single and multi-unit spiking activity. We'll be loose with terminology and use the term \"neuron\" and \"unit\" interchangeably here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfa38e2",
   "metadata": {},
   "source": [
    "## 2. Load the dataset\n",
    "\n",
    "The dataset is provided as a numpy .npz archive with the following variables:\n",
    "  \n",
    "1. `FR`: A numpy array of (neuron, time-bin, trial) with size (190, 155, 1127). The trials have already been time aligned, such that the plan and movement periods begin in the same time-bin for all of the 1127 trials.\n",
    "2. `base_idx`: Indices of time-bins corresponding to the baseline period (see Section #1).\n",
    "3. `plan_idx`: Indices of time-bins corresponding to the plan period.\n",
    "4. `move_idx`: Indices of time-bins corresponding to the movement period.\n",
    "5. `targets`: Length 8 list of the x,y coordinates for each of the 8 targets.\n",
    "5. `target_idx`: A nested list, where `cInds[0]` is list of all trials to target 1, `cInds[1]` is a list of all trials to target 2, etc.\n",
    "5. `train_idx`: Indices of the trials we will use for training.\n",
    "5. `test_idx`: Indices of the trials we will use for testing.\n",
    "  \n",
    "  \n",
    "Below, after we pull out the data, we visualize the spike data for the first trials.\n",
    "We see that there is a noticeable increase in neural activity when the movement period starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7622ef0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/Bantin/Documents/Stanford/Linderman-Shenoy/Kemere2008/extracted_data/H1217/H1217_hmm_data.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m DATA_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/Bantin/Documents/Stanford/Linderman-Shenoy/Kemere2008/extracted_data/H1217/H1217_hmm_data.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m vars_dict \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(DATA_PATH, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ssm-docs/lib/python3.9/site-packages/autograd/tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ssm-docs/lib/python3.9/site-packages/numpy/lib/npyio.py:390\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    388\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    391\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/Bantin/Documents/Stanford/Linderman-Shenoy/Kemere2008/extracted_data/H1217/H1217_hmm_data.npz'"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/Users/Bantin/Documents/Stanford/Linderman-Shenoy/Kemere2008/extracted_data/H1217/H1217_hmm_data.npz\"\n",
    "vars_dict = np.load(DATA_PATH, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d974a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FR = vars_dict['FR']\n",
    "base_idx = vars_dict['base_idx']\n",
    "plan_idx = vars_dict['plan_idx']\n",
    "move_idx = vars_dict['move_idx']\n",
    "targets = vars_dict['targets']\n",
    "target_idx = vars_dict['target_idx']\n",
    "train_idx = vars_dict['train_idx']\n",
    "test_idx = vars_dict['test_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a79c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a spike raster of the image\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.imshow(FR[:,:,1], aspect='auto', cmap='gray')\n",
    "#plt.axis('off')\n",
    "\n",
    "# Label the different phases of the trial movement activity\n",
    "time_bins = FR.shape[1]\n",
    "plan_start = plan_idx[0]\n",
    "move_start = move_idx[0]\n",
    "\n",
    "plt.axvline(x=plan_start, color='red', linewidth=5, label='Plan Start')\n",
    "plt.axvline(x=move_start, color='blue', linewidth=5, label='Move Start')\n",
    "plt.ylabel(\"Unit\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.legend()\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbacb26",
   "metadata": {},
   "source": [
    "## 3. Visualize the Targets\n",
    "To get a sense of the task, we'll visualize the 8 targets used in the task. Inspecting the `targets` array, we see \n",
    "8 pairs of (x, y) coordinates. These correspond to the location of the 8 targets on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36367b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_targets = len(targets)\n",
    "xlist = [target[0] for target in targets]\n",
    "ylist = [target[1] for target in targets]\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(xlist,\n",
    "            ylist,\n",
    "            marker='o',\n",
    "            s=10**3,\n",
    "            edgecolors='black',\n",
    "            facecolors='gray')\n",
    "plt.xlim(-150, 150)\n",
    "plt.ylim(-150, 150)\n",
    "\n",
    "for i in range(num_targets):\n",
    "    plt.annotate(str(i+1),\n",
    "                 (xlist[i] - 5, ylist[i]),\n",
    "                 color='white',\n",
    "                 weight='bold',\n",
    "                 size=16)\n",
    "plt.title(\"Target Locations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eb2e39",
   "metadata": {},
   "source": [
    "## 4. Fit a simple 3-state HMM\n",
    "As a first step, we'll fit a simple 3 state HMM to the training data. For this, we're not aiming to actually decode which target the monkey reached to, we're merely going to check if we can uncover the the 3 phases of the reach (baseline, plan, move) in an unsupervised way using an HMM.\n",
    "  \n",
    "### 4.1 Format the data for SSM\n",
    "When calling SSM's `fit` function, the data is expected to be formatted as a list `datas` where `datas[i]` is a 2D array of size `time_bins X observations`. Here, we'll reformat our data to match this. For us, this means that each entry of datas should be a `time_bins X 190`, because we have 190 neurons.\n",
    "\n",
    "\n",
    "In order for the following steps to make sense, we need to give more details about how the `FR` array is arranged. As mentioned, it is formatted as (neurons, time, trials). However, not every trial in the dataset is actually the same length -- this is because the length of the delay period is randomized, and it takes the monkey varying amounts of time to reach the target.  \n",
    "\n",
    "To acount for this, the `FR` array has been padded with NaNs so that all trials have the same length. This is very helpful, because it makes it easy to know which time bins correspond to each phase of the task. \n",
    "However, for our purposes, we don't want to include the NaNS when fitting our HMM (in fact, SSM will throw an error if we do). \n",
    "Instead, we will remove the columns of FR which contain NaNs, and create a list that matches the format above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b20e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_spikes(FR, idx):\n",
    "    datas = []\n",
    "    for i in idx:\n",
    "        spikes_cur = np.squeeze(FR[:,:,i])\n",
    "\n",
    "        # remove columns which contain NaNs\n",
    "        idx_keep = np.invert(np.any(np.isnan(spikes_cur), axis=0))\n",
    "        spikes_cur = spikes_cur[:,idx_keep]\n",
    "\n",
    "        # Transpose the data for passing to SSM fit function\n",
    "        # To use the Poisson observation model, we must also\n",
    "        # convert our arrays to be integer types.\n",
    "        datas.append(np.asarray(spikes_cur.T, dtype=int))\n",
    "    return datas\n",
    "\n",
    "# We get the indices of all reaches to the left as target_inds[0]\n",
    "# and all reaches to the right as target_inds[7]\n",
    "left_reach_idx = set(target_idx[1])\n",
    "right_reach_idx = set(target_idx[7])\n",
    "\n",
    "train_right_idx = list(right_reach_idx.intersection(train_idx))\n",
    "train_left_idx = list(left_reach_idx.intersection(train_idx))\n",
    "\n",
    "test_right_idx = list(right_reach_idx.intersection(test_idx))\n",
    "test_left_idx = list(left_reach_idx.intersection(test_idx))\n",
    "\n",
    "train_idx_combined = train_right_idx + train_left_idx\n",
    "test_idx_combined = test_right_idx + test_left_idx\n",
    "\n",
    "train_datas = format_spikes(FR, train_idx_combined)\n",
    "test_datas = format_spikes(FR, test_idx_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a3dc28",
   "metadata": {},
   "source": [
    "### 4.2 Fit a simple 5-state HMM\n",
    "\n",
    "**Assigning States and initializing the transition Matrix**\n",
    "  \n",
    "For this, we'll replicate Figure 3 in the paper. We'll fit a simple 5 state HMM with 1 baseline state, and 2-states each for reaches to the left and right (plan and move). We will assign our states as follows:\n",
    "\n",
    "1. Baseline\n",
    "2. Planning Right\n",
    "3. Reaching Right\n",
    "4. Planning Left\n",
    "5. Reaching Left\n",
    "\n",
    "We then need to initialize the transition matrix A, along with the mean firing rates for each state.\n",
    "We initialize $A$ as follows:\n",
    "\n",
    "$A = \\begin{bmatrix}\n",
    "0.8 & 0.1 & 0 & 0.1 & 0 \\\\\n",
    "0   & 0.9 & 0.1 & 0 & 0 \\\\\n",
    "0   & 0   & 1   & 0 & 0 \\\\\n",
    "0   & 0   & 0 & 0.9 & 0.1\\\\\n",
    "0   & 0   & 0  &   0 & 1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "**Constraining the HMM to avoid certain transitions**  \n",
    "  \n",
    "We want our HMM to be a \"left-to-right\" HMM because certain transitions are not allowed (e.g transitioning from \"plan right\" to \"move left\"). To do so we will use the `constrained` transitions class. This class allows us to specify which elements of the transition matrix are allowed to be non-zero.\n",
    "\n",
    "To use the `constrained` transitions class, we will also need to provide SSM with a transition mask. This will tell SSM which entries are allowed to be nonzero. The mask must be an array of booleans that is $K x K$. Entries of the mask that are zero will force zeros in the transition matrix at corresponding locations.\n",
    "\n",
    "We then pass in the transitions mask as `transition_kwargs` inside of a dictionary:\n",
    "\n",
    "```python\n",
    "transition_mask = (A > 0)\n",
    "transition_kwargs = {\"transition_mask\": transition_mask}\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**Creating an HMM Object**\n",
    "\n",
    "The syntax to create a standard HMM object using SSM is:  \n",
    "`ssm.HMM(K, N, transitions=<transition_class>, observations=<observation_class>)`\n",
    "\n",
    "We can manually set the state transition matrix using:  \n",
    "`simple_hmm.transitions.log_Ps = log_A`\n",
    "\n",
    "Where $K$ is the number of discrete states, and $N$ is the dimensensionality of the observations. We'll use standard transitions and Poisson observations.\n",
    "To fit our HMM to the training data, we call `HMM.fit(train_trials, masks=train_masks)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f637c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = 5\n",
    "num_neurons = train_datas[0].shape[1]\n",
    "\n",
    "# Manually set the initial state distribution\n",
    "init_dist = ssm.init_state_distns.FixedInitialStateDistribution(num_states,\n",
    "                                                                num_neurons,\n",
    "                                                                pi0 = np.array([1, 0, 0, 0, 0]))\n",
    "\n",
    "\n",
    "# Manually initialize the means for each state\n",
    "lambdas_baseline = np.nanmean(FR[:,base_idx,:], axis=(1,2))\n",
    "left_trials = FR[:,:,train_left_idx]\n",
    "right_trials = FR[:,:,train_right_idx]\n",
    "\n",
    "lambdas_plan_left = np.nanmean(left_trials[:,plan_idx,:], axis=(1,2))\n",
    "lambdas_move_left = np.nanmean(left_trials[:,move_idx,:], axis=(1,2))\n",
    "\n",
    "lambdas_plan_right = np.nanmean(right_trials[:,plan_idx,:], axis=(1,2))\n",
    "lambdas_move_right = np.nanmean(right_trials[:,move_idx,:], axis=(1,2))\n",
    "\n",
    "lambdas = np.vstack((lambdas_baseline,\n",
    "                     lambdas_plan_right,\n",
    "                     lambdas_move_right,\n",
    "                     lambdas_plan_left,\n",
    "                     lambdas_move_left))\n",
    "\n",
    "# Manually initialize the transition probabilities\n",
    "A = np.array(\n",
    "[[0.8, 0.1, 0, 0.1, 0],\n",
    "[0, 0.9, 0.1, 0, 0],\n",
    "[0, 0, 1, 0, 0],\n",
    "[0, 0, 0, 0.9, 0.1],\n",
    "[0, 0, 0, 0, 1]]\n",
    ")\n",
    "\n",
    "# Create our HMM\n",
    "transition_mask = (A > 0)\n",
    "transition_kwargs = {\"transition_mask\": transition_mask}\n",
    "simple_hmm = ssm.HMM(num_states,\n",
    "                     num_neurons,\n",
    "                     observations=\"poisson\",\n",
    "                     transitions=\"constrained\",\n",
    "                     init_state_distn=init_dist,\n",
    "                     transition_kwargs=transition_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd4ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_hmm.log_lambdas = np.log(lambdas)\n",
    "simple_hmm.transitions.log_Ps = np.log(A)\n",
    "lls = simple_hmm.fit(train_datas, method='em')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0055a1ab",
   "metadata": {},
   "source": [
    "## 4.3 Visualize the posterior likelihood over the states\n",
    "\n",
    "We would expect that transitions from \"baseline\" to \"plan\" and from \"plan\" to \"reach\" should occur roughly when the target first appears, and when the go-cue comes on, respectively. Indeed, that is what we tend to find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa18bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random reach\n",
    "test_trial_spikes = np.random.choice(test_datas)\n",
    "posterior = simple_hmm.filter(test_trial_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9642af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot posterior of states for a single test trial\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(num_states):\n",
    "    plt.plot(posterior[:,i], label=\"State %d\" % i)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26adf854",
   "metadata": {},
   "source": [
    "## 5. Decode Reach Directions\n",
    "  \n",
    "  \n",
    "For the purposes of this notebook, we are only going to decode reaches to the left and right targets (we excluded trials to other targets during the data formatting above). To so so, we'll call `hmm.filter` on each spike train in our test dataset. We'll then integrate over  window towards the end of the trial (let's say 50 ms) and pick the state that has the highest posterior probability.\n",
    "\n",
    "Recalling from above, we have assigned the states as follows: \n",
    "We will assign our states as follows:\n",
    "\n",
    "1. Baseline\n",
    "2. Planning Right\n",
    "3. Reaching Right\n",
    "4. Planning Left\n",
    "5. Reaching Left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f24a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on rightward reaches\n",
    "window = 50\n",
    "all_trials = format_spikes(FR, np.arange(FR.shape[-1]))\n",
    "num_correct = 0\n",
    "total_test_trials = len(test_right_idx) + len(test_left_idx)\n",
    "\n",
    "for i in test_right_idx:\n",
    "    trial = all_trials[i]\n",
    "    posterior = simple_hmm.filter(trial)\n",
    "    \n",
    "    # Integrate posterior probability\n",
    "    p_right = np.sum(posterior[-window:, 2])\n",
    "    p_left = np.sum(posterior[-window:, 4])\n",
    "        \n",
    "    if p_right > p_left: \n",
    "        num_correct += 1\n",
    "        \n",
    "# Now check accuracy on leftward reaches\n",
    "for i in test_left_idx:\n",
    "    trial = all_trials[i]\n",
    "    posterior = simple_hmm.filter(trial)\n",
    "    \n",
    "    # Integrate posterior probability\n",
    "    p_right = np.sum(posterior[-window:, 2])\n",
    "    p_left = np.sum(posterior[-window:, 4])\n",
    "        \n",
    "    if p_right < p_left: \n",
    "        num_correct += 1\n",
    "        \n",
    "print(\"Percent accuracy on test set %f\" % (num_correct / total_test_trials * 100))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.14.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "source_map": [
   12,
   28,
   36,
   54,
   73,
   78,
   89,
   107,
   113,
   135,
   150,
   182,
   233,
   280,
   284,
   290,
   296,
   302,
   318
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}